{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h2>Notebook details</h2>\n",
    "\n",
    "<p> This notebook is for <b>data wranging for Machine learning</b> for <b>Mortagage custome segementation</b> project.</p>\n",
    "\n",
    "<p> Notes.</p>\n",
    "<ol>\n",
    "<li>Extract all the required columns into dummy</li>\n",
    "<li>Extract the salary and loan amount column in dummy range columns </li>\n",
    "<li>Create new column accepted based on application accepted or denied by applicants</li>\n",
    "<li> Extract data into 2 pickle files\n",
    "    <ul>\n",
    "     <li>File with income and loan amount as the individual columns </li>\n",
    "     <li>File with income and loan amount as the range based dummy columns </li>\n",
    "    </ul>\n",
    "</li>        \n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting some initial values and reading data from pickle file\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pickle_file='df_selectdata_hmda_cenus.sa'\n",
    "df_selectdata = pickle.load( open( pickle_file, \"rb\" ) )\n",
    "#df_final_months.info()\n",
    "#df_final_months.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 31630026 entries, 0 to 49681\n",
      "Data columns (total 21 columns):\n",
      "Year                    int64\n",
      "PropertyType            int64\n",
      "LoanPurpose             float64\n",
      "Occupancy               float64\n",
      "LoanAmount              float64\n",
      "ActionType              float64\n",
      "MSA                     float64\n",
      "StateCode               float64\n",
      "CountyCode              float64\n",
      "ApplicantEthnicity      float64\n",
      "CoApplicantEthnicity    float64\n",
      "ApplicantRace           float64\n",
      "CoApplicantRace         float64\n",
      "ApplicantSex            float64\n",
      "CoApplicantSex          float64\n",
      "ApplicantIncome         float64\n",
      "PurchaserType           float64\n",
      "StateName               object\n",
      "CountyName              object\n",
      "CLASSCODEFIPS           object\n",
      "Result                  int64\n",
      "dtypes: float64(15), int64(3), object(3)\n",
      "memory usage: 5.2+ GB\n"
     ]
    }
   ],
   "source": [
    "df_selectdata.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to convert the category column into dummy columns \n",
    "def AddDummyColumnsToDataFrame(dfinput,colname,removelastdummy=False):\n",
    "    print('Add {}'.format(colname))\n",
    "    temp =pd.get_dummies(dfinput[colname])\n",
    "    # remove one column from dummies with least value.\n",
    "  \n",
    "    if removelastdummy:\n",
    "        t=dfinput.groupby(colname).count().state\n",
    "        col_name=((t[t.values==t.min()]).index).get_values()[0]\n",
    "        if col_name in temp.columns:\n",
    "            print('removed column {}'.format(col_name))\n",
    "            temp=temp.drop([col_name], axis=1)\n",
    "    \n",
    "    # remove the main column after extracting dummy\n",
    "    if colname in dfinput.columns:\n",
    "        print('removed column {}'.format(colname))\n",
    "        dfinput =dfinput.drop([colname], axis=1)\n",
    "    for col in temp:\n",
    "        temp.rename(columns={col: colname+'_'+str(col)}, inplace=True)\n",
    "    \n",
    "    return  pd.concat([dfinput,temp], axis=1,ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to create column value based on applicant accepted or rejected loan application\n",
    "def createResultCol(row):\n",
    "    if (row.ActionType==1 ):\n",
    "        row.Accepted=1\n",
    "    elif (row.ActionType==2 ):\n",
    "        row.Accepted=0\n",
    "    elif (row.ActionType==3 ):\n",
    "        row.Accepted=-1\n",
    "    elif (row.ActionType==4 ):\n",
    "        row.Accepted=0        \n",
    "    elif (row.ActionType==5 ):\n",
    "        row.Accepted=np.NAN\n",
    "    elif (row.ActionType==6 ):\n",
    "        row.Accepted=1\n",
    "    elif (row.ActionType==7 ):\n",
    "        row.Accepted=-1\n",
    "    elif (row.ActionType==8 ):\n",
    "        row.Accepted=0        \n",
    "    else:\n",
    "        row.Accepted=np.NAN\n",
    "    return row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out suspened, cancelled and live projects\n",
    "#Type of Action Taken* (1,6)** Yes (2,8,4) ** No (3,7)**denied (5)*****NA\n",
    "df_selectdata['Accepted']=0\n",
    "df_selectdata_ML=df_selectdata.apply(createResultCol,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StateCode\n",
      "Add StateCode\n",
      "removed column StateCode\n",
      "ApplicantEthnicity\n",
      "Add ApplicantEthnicity\n",
      "removed column ApplicantEthnicity\n",
      "ApplicantRace\n",
      "Add ApplicantRace\n",
      "removed column ApplicantRace\n",
      "ApplicantSex\n",
      "Add ApplicantSex\n",
      "removed column ApplicantSex\n",
      "Occupancy\n",
      "Add Occupancy\n",
      "removed column Occupancy\n",
      "PropertyType\n",
      "Add PropertyType\n",
      "removed column PropertyType\n",
      "LoanPurpose\n",
      "Add LoanPurpose\n",
      "removed column LoanPurpose\n"
     ]
    }
   ],
   "source": [
    "# Convert category columns to dummy columns=\n",
    "#df_selectdata_ML=df_selectdata\n",
    "categoryColumns=['StateCode','ApplicantEthnicity','ApplicantRace','ApplicantSex','Occupancy','PropertyType','LoanPurpose']\n",
    "for col in categoryColumns:\n",
    "    print(col)\n",
    "    df_selectdata_ML=AddDummyColumnsToDataFrame(df_selectdata_ML,col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for loan amount\n",
    "df_selectdata_ML=df_selectdata_ML.assign(SAL_0_50=((df_selectdata_ML['ApplicantIncome']>0) & (df_selectdata_ML['ApplicantIncome']<=50)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(SAL_50_100=((df_selectdata_ML['ApplicantIncome']>50) & (df_selectdata_ML['ApplicantIncome']<=100)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(SAL_100_150=((df_selectdata_ML['ApplicantIncome']>100) & (df_selectdata_ML['ApplicantIncome']<=150)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(SAL_150_200=((df_selectdata_ML['ApplicantIncome']>150) & (df_selectdata_ML['ApplicantIncome']<=200)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(SAL_200_250=((df_selectdata_ML['ApplicantIncome']>200) & (df_selectdata_ML['ApplicantIncome']<=250)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(SAL_250_300=((df_selectdata_ML['ApplicantIncome']>250) & (df_selectdata_ML['ApplicantIncome']<=300)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(SAL_300_350=((df_selectdata_ML['ApplicantIncome']>300) & (df_selectdata_ML['ApplicantIncome']<=350)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(SAL_350_400=((df_selectdata_ML['ApplicantIncome']>350) & (df_selectdata_ML['ApplicantIncome']<=400)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(SAL_400_450=((df_selectdata_ML['ApplicantIncome']>400) & (df_selectdata_ML['ApplicantIncome']<=450)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(SAL_450_500=((df_selectdata_ML['ApplicantIncome']>450) & (df_selectdata_ML['ApplicantIncome']<=500)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(SAL_500_5500=((df_selectdata_ML['ApplicantIncome']>500) & (df_selectdata_ML['ApplicantIncome']<=5500)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(SAL_5500_999999=((df_selectdata_ML['ApplicantIncome']>5500) & (df_selectdata_ML['ApplicantIncome']<=999999)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selectdata_ML['SAL_0_50'] = (df_selectdata_ML['SAL_0_50'] == True).astype(int)\n",
    "df_selectdata_ML['SAL_50_100'] = (df_selectdata_ML['SAL_50_100'] == True).astype(int)\n",
    "df_selectdata_ML['SAL_100_150'] = (df_selectdata_ML['SAL_100_150'] == True).astype(int)\n",
    "df_selectdata_ML['SAL_150_200'] = (df_selectdata_ML['SAL_150_200'] == True).astype(int)\n",
    "df_selectdata_ML['SAL_200_250'] = (df_selectdata_ML['SAL_200_250'] == True).astype(int)\n",
    "df_selectdata_ML['SAL_250_300'] = (df_selectdata_ML['SAL_250_300'] == True).astype(int)\n",
    "df_selectdata_ML['SAL_300_350'] = (df_selectdata_ML['SAL_300_350'] == True).astype(int)\n",
    "df_selectdata_ML['SAL_350_400'] = (df_selectdata_ML['SAL_350_400'] == True).astype(int)\n",
    "df_selectdata_ML['SAL_400_450'] = (df_selectdata_ML['SAL_400_450'] == True).astype(int)\n",
    "df_selectdata_ML['SAL_450_500'] = (df_selectdata_ML['SAL_450_500'] == True).astype(int)\n",
    "df_selectdata_ML['SAL_500_5500'] = (df_selectdata_ML['SAL_500_5500'] == True).astype(int)\n",
    "df_selectdata_ML['SAL_5500_999999'] = (df_selectdata_ML['SAL_5500_999999'] == True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for loan amount\n",
    "df_selectdata_ML=df_selectdata_ML.assign(LonAmt_0_50=((df_selectdata_ML['LoanAmount']>0) & (df_selectdata_ML['LoanAmount']<=50)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(LonAmt_50_100=((df_selectdata_ML['LoanAmount']>50) & (df_selectdata_ML['LoanAmount']<=100)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(LonAmt_100_150=((df_selectdata_ML['LoanAmount']>100) & (df_selectdata_ML['LoanAmount']<=150)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(LonAmt_150_200=((df_selectdata_ML['LoanAmount']>150) & (df_selectdata_ML['LoanAmount']<=200)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(LonAmt_200_250=((df_selectdata_ML['LoanAmount']>200) & (df_selectdata_ML['LoanAmount']<=250)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(LonAmt_250_300=((df_selectdata_ML['LoanAmount']>250) & (df_selectdata_ML['LoanAmount']<=300)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(LonAmt_300_350=((df_selectdata_ML['LoanAmount']>300) & (df_selectdata_ML['LoanAmount']<=350)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(LonAmt_350_400=((df_selectdata_ML['LoanAmount']>350) & (df_selectdata_ML['LoanAmount']<=400)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(LonAmt_400_450=((df_selectdata_ML['LoanAmount']>400) & (df_selectdata_ML['LoanAmount']<=450)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(LonAmt_450_500=((df_selectdata_ML['LoanAmount']>450) & (df_selectdata_ML['LoanAmount']<=500)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(LonAmt_500_5500=((df_selectdata_ML['LoanAmount']>500) & (df_selectdata_ML['LoanAmount']<=5500)))\n",
    "df_selectdata_ML=df_selectdata_ML.assign(LonAmt_5500_999999=((df_selectdata_ML['LoanAmount']>5500) & (df_selectdata_ML['LoanAmount']<=999999)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selectdata_ML['LonAmt_0_50'] = (df_selectdata_ML['LonAmt_0_50'] == True).astype(int)\n",
    "df_selectdata_ML['LonAmt_50_100'] = (df_selectdata_ML['LonAmt_50_100'] == True).astype(int)\n",
    "df_selectdata_ML['LonAmt_100_150'] = (df_selectdata_ML['LonAmt_100_150'] == True).astype(int)\n",
    "df_selectdata_ML['LonAmt_150_200'] = (df_selectdata_ML['LonAmt_150_200'] == True).astype(int)\n",
    "df_selectdata_ML['LonAmt_200_250'] = (df_selectdata_ML['LonAmt_200_250'] == True).astype(int)\n",
    "df_selectdata_ML['LonAmt_250_300'] = (df_selectdata_ML['LonAmt_250_300'] == True).astype(int)\n",
    "df_selectdata_ML['LonAmt_300_350'] = (df_selectdata_ML['LonAmt_300_350'] == True).astype(int)\n",
    "df_selectdata_ML['LonAmt_350_400'] = (df_selectdata_ML['LonAmt_350_400'] == True).astype(int)\n",
    "df_selectdata_ML['LonAmt_400_450'] = (df_selectdata_ML['LonAmt_400_450'] == True).astype(int)\n",
    "df_selectdata_ML['LonAmt_450_500'] = (df_selectdata_ML['LonAmt_450_500'] == True).astype(int)\n",
    "df_selectdata_ML['LonAmt_500_5500'] = (df_selectdata_ML['LonAmt_500_5500'] == True).astype(int)\n",
    "df_selectdata_ML['LonAmt_5500_999999'] = (df_selectdata_ML['LonAmt_5500_999999'] == True).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 31630026 entries, 0 to 49681\n",
      "Columns: 115 entries, Year to LonAmt_5500_999999\n",
      "dtypes: float64(9), int32(24), int64(3), object(3), uint8(76)\n",
      "memory usage: 8.8+ GB\n"
     ]
    }
   ],
   "source": [
    "df_selectdata_ML.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selectdata_ML_sel=df_selectdata_ML#.iloc[:,13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selectdata_ML_sel=df_selectdata_ML_sel.drop('CoApplicantEthnicity',axis=1)\n",
    "df_selectdata_ML_sel=df_selectdata_ML_sel.drop('CoApplicantRace',axis=1)\n",
    "df_selectdata_ML_sel=df_selectdata_ML_sel.drop('CoApplicantSex',axis=1)\n",
    "df_selectdata_ML_sel=df_selectdata_ML_sel.drop('CLASSCODEFIPS',axis=1)\n",
    "df_selectdata_ML_sel=df_selectdata_ML_sel.drop('ActionType',axis=1)\n",
    "df_selectdata_ML_sel=df_selectdata_ML_sel.drop('MSA',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selectdata_ML_sel=df_selectdata_ML_sel.loc[:,['Year',\n",
    "'CountyCode',\n",
    "'PurchaserType',\n",
    "'StateName',\n",
    "'CountyName',\n",
    "'Result',\n",
    "'Accepted',\n",
    "'StateCode_1.0',\n",
    "'StateCode_2.0',\n",
    "'StateCode_4.0',\n",
    "'StateCode_5.0',\n",
    "'StateCode_6.0',\n",
    "'StateCode_8.0',\n",
    "'StateCode_9.0',\n",
    "'StateCode_10.0',\n",
    "'StateCode_11.0',\n",
    "'StateCode_12.0',\n",
    "'StateCode_13.0',\n",
    "'StateCode_15.0',\n",
    "'StateCode_16.0',\n",
    "'StateCode_17.0',\n",
    "'StateCode_18.0',\n",
    "'StateCode_19.0',\n",
    "'StateCode_20.0',\n",
    "'StateCode_21.0',\n",
    "'StateCode_22.0',\n",
    "'StateCode_23.0',\n",
    "'StateCode_24.0',\n",
    "'StateCode_25.0',\n",
    "'StateCode_26.0',\n",
    "'StateCode_27.0',\n",
    "'StateCode_28.0',\n",
    "'StateCode_29.0',\n",
    "'StateCode_30.0',\n",
    "'StateCode_31.0',\n",
    "'StateCode_32.0',\n",
    "'StateCode_33.0',\n",
    "'StateCode_34.0',\n",
    "'StateCode_35.0',\n",
    "'StateCode_36.0',\n",
    "'StateCode_37.0',\n",
    "'StateCode_38.0',\n",
    "'StateCode_39.0',\n",
    "'StateCode_40.0',\n",
    "'StateCode_41.0',\n",
    "'StateCode_42.0',\n",
    "'StateCode_44.0',\n",
    "'StateCode_45.0',\n",
    "'StateCode_46.0',\n",
    "'StateCode_47.0',\n",
    "'StateCode_48.0',\n",
    "'StateCode_49.0',\n",
    "'StateCode_50.0',\n",
    "'StateCode_51.0',\n",
    "'StateCode_53.0',\n",
    "'StateCode_54.0',\n",
    "'StateCode_55.0',\n",
    "'StateCode_56.0',\n",
    "'StateCode_72.0',\n",
    "'StateCode_78.0',\n",
    "'ApplicantEthnicity_1.0',\n",
    "'ApplicantEthnicity_2.0',\n",
    "'ApplicantEthnicity_3.0',\n",
    "'ApplicantEthnicity_4.0',\n",
    "'ApplicantRace_1.0',\n",
    "'ApplicantRace_2.0',\n",
    "'ApplicantRace_3.0',\n",
    "'ApplicantRace_4.0',\n",
    "'ApplicantRace_5.0',\n",
    "'ApplicantRace_6.0',\n",
    "'ApplicantRace_7.0',\n",
    "'ApplicantSex_1.0',\n",
    "'ApplicantSex_2.0',\n",
    "'ApplicantSex_3.0',\n",
    "'ApplicantSex_4.0',\n",
    "'Occupancy_1.0',\n",
    "'Occupancy_2.0',\n",
    "'Occupancy_3.0',\n",
    "'PropertyType_1',\n",
    "'PropertyType_2',\n",
    "'LoanPurpose_1.0',\n",
    "'LoanPurpose_2.0',\n",
    "'LoanPurpose_3.0',  \n",
    "'SAL_0_50',\n",
    "'SAL_50_100',\n",
    "'SAL_100_150',\n",
    "'SAL_150_200',\n",
    "'SAL_200_250',\n",
    "'SAL_250_300',\n",
    "'SAL_300_350',\n",
    "'SAL_350_400',\n",
    "'SAL_400_450',\n",
    "'SAL_450_500',\n",
    "'SAL_500_5500',\n",
    "'SAL_5500_999999',\n",
    "'LonAmt_0_50',\n",
    "'LonAmt_50_100',\n",
    "'LonAmt_100_150',\n",
    "'LonAmt_150_200',\n",
    "'LonAmt_200_250',\n",
    "'LonAmt_250_300',\n",
    "'LonAmt_300_350',\n",
    "'LonAmt_350_400',\n",
    "'LonAmt_400_450',\n",
    "'LonAmt_450_500',\n",
    "'LonAmt_500_5500',\n",
    "'LonAmt_5500_999999']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Year',\n",
      "'LoanAmount',\n",
      "'CountyCode',\n",
      "'ApplicantIncome',\n",
      "'PurchaserType',\n",
      "'StateName',\n",
      "'CountyName',\n",
      "'Result',\n",
      "'Accepted',\n",
      "'StateCode_1.0',\n",
      "'StateCode_2.0',\n",
      "'StateCode_4.0',\n",
      "'StateCode_5.0',\n",
      "'StateCode_6.0',\n",
      "'StateCode_8.0',\n",
      "'StateCode_9.0',\n",
      "'StateCode_10.0',\n",
      "'StateCode_11.0',\n",
      "'StateCode_12.0',\n",
      "'StateCode_13.0',\n",
      "'StateCode_15.0',\n",
      "'StateCode_16.0',\n",
      "'StateCode_17.0',\n",
      "'StateCode_18.0',\n",
      "'StateCode_19.0',\n",
      "'StateCode_20.0',\n",
      "'StateCode_21.0',\n",
      "'StateCode_22.0',\n",
      "'StateCode_23.0',\n",
      "'StateCode_24.0',\n",
      "'StateCode_25.0',\n",
      "'StateCode_26.0',\n",
      "'StateCode_27.0',\n",
      "'StateCode_28.0',\n",
      "'StateCode_29.0',\n",
      "'StateCode_30.0',\n",
      "'StateCode_31.0',\n",
      "'StateCode_32.0',\n",
      "'StateCode_33.0',\n",
      "'StateCode_34.0',\n",
      "'StateCode_35.0',\n",
      "'StateCode_36.0',\n",
      "'StateCode_37.0',\n",
      "'StateCode_38.0',\n",
      "'StateCode_39.0',\n",
      "'StateCode_40.0',\n",
      "'StateCode_41.0',\n",
      "'StateCode_42.0',\n",
      "'StateCode_44.0',\n",
      "'StateCode_45.0',\n",
      "'StateCode_46.0',\n",
      "'StateCode_47.0',\n",
      "'StateCode_48.0',\n",
      "'StateCode_49.0',\n",
      "'StateCode_50.0',\n",
      "'StateCode_51.0',\n",
      "'StateCode_53.0',\n",
      "'StateCode_54.0',\n",
      "'StateCode_55.0',\n",
      "'StateCode_56.0',\n",
      "'StateCode_72.0',\n",
      "'StateCode_78.0',\n",
      "'ApplicantEthnicity_1.0',\n",
      "'ApplicantEthnicity_2.0',\n",
      "'ApplicantEthnicity_3.0',\n",
      "'ApplicantEthnicity_4.0',\n",
      "'ApplicantRace_1.0',\n",
      "'ApplicantRace_2.0',\n",
      "'ApplicantRace_3.0',\n",
      "'ApplicantRace_4.0',\n",
      "'ApplicantRace_5.0',\n",
      "'ApplicantRace_6.0',\n",
      "'ApplicantRace_7.0',\n",
      "'ApplicantSex_1.0',\n",
      "'ApplicantSex_2.0',\n",
      "'ApplicantSex_3.0',\n",
      "'ApplicantSex_4.0',\n",
      "'Occupancy_1.0',\n",
      "'Occupancy_2.0',\n",
      "'Occupancy_3.0',\n",
      "'PropertyType_1',\n",
      "'PropertyType_2',\n",
      "'LoanPurpose_1.0',\n",
      "'LoanPurpose_2.0',\n",
      "'LoanPurpose_3.0',\n",
      "'SAL_0_50',\n",
      "'SAL_50_100',\n",
      "'SAL_100_150',\n",
      "'SAL_150_200',\n",
      "'SAL_200_250',\n",
      "'SAL_250_300',\n",
      "'SAL_300_350',\n",
      "'SAL_350_400',\n",
      "'SAL_400_450',\n",
      "'SAL_450_500',\n",
      "'SAL_500_5500',\n",
      "'SAL_5500_999999',\n",
      "'LonAmt_0_50',\n",
      "'LonAmt_50_100',\n",
      "'LonAmt_100_150',\n",
      "'LonAmt_150_200',\n",
      "'LonAmt_200_250',\n",
      "'LonAmt_250_300',\n",
      "'LonAmt_300_350',\n",
      "'LonAmt_350_400',\n",
      "'LonAmt_400_450',\n",
      "'LonAmt_450_500',\n",
      "'LonAmt_500_5500',\n",
      "'LonAmt_5500_999999',\n"
     ]
    }
   ],
   "source": [
    "for col in df_selectdata_ML_sel:\n",
    "    print(\"'\"+col+\"',\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_selectdata_ML.sa\n"
     ]
    }
   ],
   "source": [
    "#df_selecteddata.info()\n",
    "picklefilename='df_selectdata_ML.sa'\n",
    "# get the pickle file name to re confirm the previous files are not overriden.\n",
    "# Note: Run this file after confimring succesful completion of all above steps\n",
    "print(picklefilename)\n",
    "# create pickle file for further use \n",
    "pickle.dump(df_selectdata_ML_sel,open(picklefilename,'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe with salary and loan amount as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selectdata_ML_sel=df_selectdata_ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selectdata_ML_sel=df_selectdata_ML_sel.drop('CoApplicantEthnicity',axis=1)\n",
    "df_selectdata_ML_sel=df_selectdata_ML_sel.drop('CoApplicantRace',axis=1)\n",
    "df_selectdata_ML_sel=df_selectdata_ML_sel.drop('CoApplicantSex',axis=1)\n",
    "df_selectdata_ML_sel=df_selectdata_ML_sel.drop('CLASSCODEFIPS',axis=1)\n",
    "df_selectdata_ML_sel=df_selectdata_ML_sel.drop('ActionType',axis=1)\n",
    "df_selectdata_ML_sel=df_selectdata_ML_sel.drop('MSA',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selectdata_ML_sel=df_selectdata_ML_sel.loc[:,['Year',\n",
    "'CountyCode',\n",
    "'PurchaserType',\n",
    "'StateName',\n",
    "'CountyName',\n",
    "'Result',\n",
    "'Accepted',\n",
    "'StateCode_1.0',\n",
    "'StateCode_2.0',\n",
    "'StateCode_4.0',\n",
    "'StateCode_5.0',\n",
    "'StateCode_6.0',\n",
    "'StateCode_8.0',\n",
    "'StateCode_9.0',\n",
    "'StateCode_10.0',\n",
    "'StateCode_11.0',\n",
    "'StateCode_12.0',\n",
    "'StateCode_13.0',\n",
    "'StateCode_15.0',\n",
    "'StateCode_16.0',\n",
    "'StateCode_17.0',\n",
    "'StateCode_18.0',\n",
    "'StateCode_19.0',\n",
    "'StateCode_20.0',\n",
    "'StateCode_21.0',\n",
    "'StateCode_22.0',\n",
    "'StateCode_23.0',\n",
    "'StateCode_24.0',\n",
    "'StateCode_25.0',\n",
    "'StateCode_26.0',\n",
    "'StateCode_27.0',\n",
    "'StateCode_28.0',\n",
    "'StateCode_29.0',\n",
    "'StateCode_30.0',\n",
    "'StateCode_31.0',\n",
    "'StateCode_32.0',\n",
    "'StateCode_33.0',\n",
    "'StateCode_34.0',\n",
    "'StateCode_35.0',\n",
    "'StateCode_36.0',\n",
    "'StateCode_37.0',\n",
    "'StateCode_38.0',\n",
    "'StateCode_39.0',\n",
    "'StateCode_40.0',\n",
    "'StateCode_41.0',\n",
    "'StateCode_42.0',\n",
    "'StateCode_44.0',\n",
    "'StateCode_45.0',\n",
    "'StateCode_46.0',\n",
    "'StateCode_47.0',\n",
    "'StateCode_48.0',\n",
    "'StateCode_49.0',\n",
    "'StateCode_50.0',\n",
    "'StateCode_51.0',\n",
    "'StateCode_53.0',\n",
    "'StateCode_54.0',\n",
    "'StateCode_55.0',\n",
    "'StateCode_56.0',\n",
    "'StateCode_72.0',\n",
    "'StateCode_78.0',\n",
    "'ApplicantEthnicity_1.0',\n",
    "'ApplicantEthnicity_2.0',\n",
    "'ApplicantEthnicity_3.0',\n",
    "'ApplicantEthnicity_4.0',\n",
    "'ApplicantRace_1.0',\n",
    "'ApplicantRace_2.0',\n",
    "'ApplicantRace_3.0',\n",
    "'ApplicantRace_4.0',\n",
    "'ApplicantRace_5.0',\n",
    "'ApplicantRace_6.0',\n",
    "'ApplicantRace_7.0',\n",
    "'ApplicantSex_1.0',\n",
    "'ApplicantSex_2.0',\n",
    "'ApplicantSex_3.0',\n",
    "'ApplicantSex_4.0',\n",
    "'Occupancy_1.0',\n",
    "'Occupancy_2.0',\n",
    "'Occupancy_3.0',\n",
    "'PropertyType_1',\n",
    "'PropertyType_2',\n",
    "'LoanPurpose_1.0',\n",
    "'LoanPurpose_2.0',\n",
    "'LoanPurpose_3.0', \n",
    "'ApplicantIncome',\n",
    "'LoanAmount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_selectdata_ML_WSA.sa\n"
     ]
    }
   ],
   "source": [
    "#df_selecteddata.info()\n",
    "picklefilename='df_selectdata_ML_WSA.sa'\n",
    "# get the pickle file name to re confirm the previous files are not overriden.\n",
    "# Note: Run this file after confimring succesful completion of all above steps\n",
    "print(picklefilename)\n",
    "# create pickle file for further use \n",
    "pickle.dump(df_selectdata_ML_sel,open(picklefilename,'wb'), protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31630026"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_selectdata_ML_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
