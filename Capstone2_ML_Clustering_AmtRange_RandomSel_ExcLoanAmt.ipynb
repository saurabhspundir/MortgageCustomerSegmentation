{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import sklearn.decomposition\n",
    "\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-info\">\n",
    "<h2>Notebook details</h2>\n",
    "\n",
    "<p> This notebook is for <b>Clustering</b> for <b>Mortagage custome segementation</b> project.</p>\n",
    "<p> The records are choosen by test and train. The loan amount is not considerd as one feature. The salary and loan are used as bins</p>\n",
    "<p> Notes.</p>\n",
    "<ol>\n",
    "<li>Apply K Mean clustering algorithm to the data</li>\n",
    "<li>Apply methods to choose best value of K</li> \n",
    "    <ul>\n",
    "     <li>The Elbow Sum-of-Squares Method</li>\n",
    "     <li>The Silhouette Method </li>\n",
    "    </ul>\n",
    "<li>Consider K Mean as baseline analysis </li>\n",
    "<li>Apply test train split to reduce data size to one million records</li>\n",
    "        \n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file='df_selectdata_ML.sa'\n",
    "df_selectdata = pickle.load( open( pickle_file, \"rb\" ) )\n",
    "#df_final_months.info()\n",
    "#df_final_months.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_selectdata.info()\n",
    "len(df_selectdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reduce the size of data set and allow the code to analyze cluster in each state the data frame filtered by State\n",
    "def getDataFrameforState(inputframe,stateName='CA'):\n",
    "    df=inputframe[inputframe.StateName==stateName]\n",
    "    df=df[df.Accepted>0]\n",
    "    df = df.reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get K mean for no of cluster \n",
    "def getKmeansForCluster(noOfCluster, randomstate=1):\n",
    "    kmean = KMeans(n_clusters=noOfCluster, random_state=randomstate)\n",
    "    return kmean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the fit predcit for k mean \n",
    "def getFitPredictForKMean(kMean,xcols):\n",
    "    kmeans_val =kMean.fit_predict(xcols)\n",
    "    return kmeans_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data frame  with PCA with component dimension and K mean for \n",
    "#one component as all x cols and another component as the unique value\n",
    "# this provides the clutser for each row in data frame \n",
    "def getPCADataFrame(noOfCluster,kmeans_val,xcols,componetNum=2):\n",
    "    pca = PCA(n_components = componetNum)\n",
    "    matrix = np.matrix(pca.fit_transform(xcols))\n",
    "    df_pca_matrix = pd.DataFrame(matrix)\n",
    "    df_pca_matrix.columns = ['x','y']\n",
    "\n",
    "    df_clusters = pd.DataFrame(df_filterdata.iloc[:,0])\n",
    "    df_clusters['x'], df_clusters['y'] = df_pca_matrix['x'], df_pca_matrix['y']\n",
    "    df_clusters['cluster_label'] = kmeans_val\n",
    "\n",
    "    return df_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method to draw average silhouette score as graph for ranges of clusterand avg score calculated\n",
    "def drawAverageSilhouetteScore(range_n_clusters,silhouette_avgscores):\n",
    "        fig, axis = plt.subplots(1,1,figsize=(6,6),dpi=100)\n",
    "        _ = plt.plot(range_n_clusters,silhouette_avgscores)\n",
    "        _ = plt.xlabel('$K$')\n",
    "        _ = plt.ylabel('Average Silhouette Score')\n",
    "        _ = plt.title('Average Silhouette Scores for KMeans clustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw bar graph for number of rows for each cluster X axis(cluster number), Y axis(no of rows in each cluster)\n",
    "def drawClusterBar(noOfCluster,kmeans_val):\n",
    "    cluster_kmeans_val = pd.Series(kmeans_val).value_counts().sort_index()\n",
    "    #print(cluster_kmeans_val5)\n",
    "\n",
    "    fig, axis = plt.subplots(1,1,figsize=(6,6),dpi=100)\n",
    "    _ = cluster_kmeans_val.plot(kind='bar')\n",
    "    _ = plt.ylabel('Number of Points')\n",
    "    _ = plt.xlabel('Cluster')\n",
    "    _ = plt.title('No of points for Clusters($K$ = '+str(noOfCluster)+')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw cluster point on graph for each cluster . depends on data frame created PCA\n",
    "def drawClusterPlot(df_clusters):\n",
    "    axis = sns.lmplot(data=df_clusters, x='x', y='y', hue='cluster_label', \n",
    "                   fit_reg=False, legend=True, legend_out=True,size=10)\n",
    "    _ = axis.set_axis_labels(\"Component 1\", \"Component 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw elbow plot to get the best component value for PCA\n",
    "def drawElbowPCAplot(xcols):\n",
    "    pca = sklearn.decomposition.PCA()\n",
    "    pca.fit(xcols)\n",
    "    fig, axis = plt.subplots(1,1,figsize=(12,6),dpi=100)\n",
    "    _ = plt.plot(pca.explained_variance_)\n",
    "    _ = plt.xlabel('$K$')\n",
    "    _ = plt.xticks(range(0,33,1))\n",
    "    _ = plt.xlim([0,31])\n",
    "    _ = plt.ylabel('Explained Variance')\n",
    "    _ = plt.title('Elbow Plot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAllcolNameforDataframe(df):\n",
    "    for col in df:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilterDatasetForRowCount(df,noofRows,random=True, samplesize=0.5):\n",
    "    if(len(df)>noofRows):\n",
    "        if(random):\n",
    "            df1,df2=train_test_split(df, shuffle=True,train_size=samplesize,test_size=samplesize)\n",
    "            if(len(df1)>noofRows):\n",
    "                df=df1.iloc[:noofRows,:]\n",
    "            else:\n",
    "                 df=(df1.append(df2,ignore_index=True)).iloc[:noofRows,:]\n",
    "        else:\n",
    "            df=df.iloc[:noofRows,:]\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 million rows extracted for state to process\n",
    "noofRows=1000000\n",
    "range_n_clusters = range(2,11)\n",
    "df_filterdata=getFilterDatasetForRowCount(getDataFrameforState(df_selectdata,'CA'),noofRows)\n",
    "df_filterdata_NR=getFilterDatasetForRowCount(getDataFrameforState(df_selectdata,'CA'),noofRows,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create common x for all further processing for all feature columns \n",
    "x_cols = np.matrix(df_filterdata.iloc[:,8:96])\n",
    "x_cols_NR = np.matrix(df_filterdata_NR.iloc[:,8:96])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_filterdata))\n",
    "print (len(df_filterdata.index.unique()))\n",
    "print(len(x_cols))\n",
    "\n",
    "print(len(df_filterdata_NR))\n",
    "print (len(df_filterdata_NR.index.unique()))\n",
    "print(len(x_cols_NR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K - Mean clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elbow Method for K \n",
    "We can plot SS vs. $K$ and choose the *elbow point* in the plot as the best value for $K$. The elbow point is the point at which the plot starts descending much more slowly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the K means for range to find out best K value for elbow method\n",
    "ss = []\n",
    "for k in range_n_clusters:\n",
    "    #kmeans = KMeans(n_clusters=k, random_state=1)\n",
    "    kmeans = getKmeansForCluster(k,x_cols)\n",
    "    kmeans.fit(x_cols)\n",
    "    #print('k='+str(k))\n",
    "    #print('inertia '+str(kmeans.inertia_))\n",
    "    ss.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(ss))\n",
    "print(min(ss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(1,1,figsize=(8,8),dpi=100)\n",
    "_ = plt.plot(range_n_clusters, ss, 'ro-', linewidth = 1.0)\n",
    "_ = plt.xlim([1,12])\n",
    "_ = plt.xlabel('K')\n",
    "_ = plt.ylim([20919354137,99045829963])\n",
    "_ = plt.ylabel('Sum of Squares(SS)')\n",
    "_ = plt.title('Elbow Method (2-10)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Silhouette Method for K \n",
    "<pre>\n",
    "\n",
    "| Range       | Interpretation                                |\n",
    "|-------------|-----------------------------------------------|\n",
    "| 0.71 - 1.0  | A strong structure has been found.            |\n",
    "| 0.51 - 0.7  | A reasonable structure has been found.        |\n",
    "| 0.26 - 0.5  | The structure is weak and could be artificial.|\n",
    "| < 0.25      | No substantial structure has been found.      |\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "silhouette_avgscores = []\n",
    "kmeans_predict_col={}\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    cluster_labels = getFitPredictForKMean(getKmeansForCluster(n_clusters),x_cols)\n",
    "    if n_clusters not in kmeans_predict_col:\n",
    "        kmeans_predict_col[n_clusters]=cluster_labels\n",
    "\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    # The sample size is used to avoid memeory error\n",
    "    silhouette_avg = silhouette_score(x_cols, cluster_labels,sample_size=50000)\n",
    "    silhouette_avgscores.append(silhouette_avg)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw graph for all above silhouette_score\n",
    "drawAverageSilhouetteScore(range_n_clusters,silhouette_avgscores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize cluster for range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for noofcluster in range_n_clusters:\n",
    "    if noofcluster in kmeans_predict_col:\n",
    "        kmeans_val=kmeans_predict_col[noofcluster]\n",
    "    else:\n",
    "        kmeans_val = getFitPredictForKMean(getKmeansForCluster(noofcluster),x_cols)\n",
    "    drawClusterBar(noofcluster,kmeans_val)\n",
    "    drawClusterPlot(getPCADataFrame(noofcluster,kmeans_val,x_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawElbowPCAplot(x_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the best Kmean and display the data frame with cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noofcluster=3\n",
    "if noofcluster in kmeans_predict_col_NR:\n",
    "    kmeans_val=kmeans_predict_col[noofcluster]\n",
    "else:\n",
    "    kmeans_val = getFitPredictForKMean(getKmeansForCluster(noofcluster),x_cols)\n",
    "drawClusterBar(noofcluster,kmeans_val)\n",
    "drawClusterPlot(getPCADataFrame(noofcluster,kmeans_val,x_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not random records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the K means for range to find out best K value for elbow method\n",
    "ss_NR = []\n",
    "for k in range_n_clusters:\n",
    "    #kmeans = KMeans(n_clusters=k, random_state=1)\n",
    "    kmeans = getKmeansForCluster(k,x_cols_NR)\n",
    "    kmeans.fit(x_cols_NR)\n",
    "    #print('k='+str(k))\n",
    "    #print('inertia '+str(kmeans.inertia_))\n",
    "    ss_NR.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max(ss_NR))\n",
    "print(min(ss_NR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axis = plt.subplots(1,1,figsize=(8,8),dpi=100)\n",
    "_ = plt.plot(range_n_clusters, ss_NR, 'ro-', linewidth = 1.0)\n",
    "_ = plt.xlim([1,12])\n",
    "_ = plt.xlabel('K')\n",
    "_ = plt.ylim([20919354137,99045829963])\n",
    "_ = plt.ylabel('Sum of Squares(SS)')\n",
    "_ = plt.title('Elbow Method (2-10)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Silhouette Method for K \n",
    "<pre>\n",
    "\n",
    "| Range       | Interpretation                                |\n",
    "|-------------|-----------------------------------------------|\n",
    "| 0.71 - 1.0  | A strong structure has been found.            |\n",
    "| 0.51 - 0.7  | A reasonable structure has been found.        |\n",
    "| 0.26 - 0.5  | The structure is weak and could be artificial.|\n",
    "| < 0.25      | No substantial structure has been found.      |\n",
    "\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_avgscores_NR = []\n",
    "# Empty dict\n",
    "kmeans_predict_col_NR = {}\n",
    "for n_clusters in range_n_clusters:\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    cluster_labels = getFitPredictForKMean(getKmeansForCluster(n_clusters),x_cols)\n",
    "    if n_clusters not in kmeans_predict_col_NR:\n",
    "        kmeans_predict_col_NR[n_clusters]=cluster_labels\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    # The sample size is used to avoid memeory error\n",
    "    silhouette_avg = silhouette_score(x_cols, cluster_labels,sample_size=50000)\n",
    "    silhouette_avgscores_NR.append(silhouette_avg)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw graph for all above silhouette_score\n",
    "drawAverageSilhouetteScore(range_n_clusters,silhouette_avgscores_NR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize cluster for range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for noofcluster in range_n_clusters:\n",
    "    if noofcluster in kmeans_predict_col_NR:\n",
    "        kmeans_val=kmeans_predict_col_NR[noofcluster]\n",
    "    else:\n",
    "        kmeans_val = getFitPredictForKMean(getKmeansForCluster(noofcluster),x_cols_NR)\n",
    "    drawClusterBar(noofcluster,kmeans_val)\n",
    "    drawClusterPlot(getPCADataFrame(noofcluster,kmeans_val,x_cols_NR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drawElbowPCAplot(x_cols_NR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the best Kmean and display the data frame with cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noofcluster=3\n",
    "if noofcluster in kmeans_predict_col_NR:\n",
    "    kmeans_val=kmeans_predict_col_NR[noofcluster]\n",
    "else:\n",
    "    kmeans_val = getFitPredictForKMean(getKmeansForCluster(noofcluster),x_cols_NR)\n",
    "drawClusterBar(noofcluster,kmeans_val)\n",
    "drawClusterPlot(getPCADataFrame(noofcluster,kmeans_val,x_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Rough work below"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#del df_selectdata\n",
    "del df_filterdata"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
